from pathlib import Path
import pandas as pd

BASE = Path("data/silver")

SPECS = [
    {
        "path": BASE / "holidays/jp_holidays_silver.csv",
        "required_cols": ["date","holiday_name","category"],
        "date_cols": ["date"],
        # åŒä¸€å¤©åŒåä¸å¯é‡è¤‡
        "unique_keys": [["date","holiday_name"]],
    },
    {
        "path": BASE / "jis/jis_prefecture_city_silver.csv",
        "required_cols": ["pref_code","pref_name","city_code","city_name"],
        "date_cols": [],
        # âœ” JIS å”¯ä¸€éµï¼šcity_codeï¼ˆå®˜æ–¹ç¢¼ï¼Œå¤©ç„¶å”¯ä¸€ï¼‰
        "unique_keys": [["city_code"]],
    },
    {
        "path": BASE / "tax/tax_rate_silver.csv",
        "required_cols": ["start_date","end_date","tax_rate"],
        "date_cols": ["start_date","end_date"],
        # ç¨…ç‡æœŸé–“å¯é‡ç–Šï¼Œä½†å–®ç´”æª¢æŸ¥èµ·æ—¥+ç¨…ç‡ä¸é‡è¤‡ï¼ˆé¬†æª¢ï¼‰
        "unique_keys": [["start_date","tax_rate"]],
    },
]

def validate_file(spec):
    p = spec["path"]
    df = pd.read_csv(p, dtype=str)

    # å¿…è¦æ¬„
    for c in spec["required_cols"]:
        assert c in df.columns, f"{p}: missing column {c}"

    # æ—¥æœŸæ¬„å¯è§£æä¸”éå…¨ç©º
    for c in spec["date_cols"]:
        parsed = pd.to_datetime(df[c], errors="coerce")
        assert parsed.notna().any(), f"{p}: column {c} all null after parse"

    # å”¯ä¸€éµ
    for key in spec["unique_keys"]:
        dup = df.duplicated(subset=key).sum()
        assert dup == 0, f"{p}: duplicated keys on {key}"

    print(f"âœ… {p}: OK ({len(df)} rows)")

def main():
    for s in SPECS:
        validate_file(s)
    print("ğŸ¯ All Silver datasets validated successfully!")

if __name__ == "__main__":
    main()
