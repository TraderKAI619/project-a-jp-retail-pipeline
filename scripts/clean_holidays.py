import pandas as pd
from pathlib import Path
import sys
import re

STAGING_DIR = Path("data/raw_official/holidays/_staging")
OUTPUT_PATH = Path("data/intermediate/holidays/jp_holidays_clean.csv")

print(f"ğŸ“¥ Looking for source in: {STAGING_DIR}")

# æ‰¾æª”æ¡ˆ
candidates = list(STAGING_DIR.glob("*.csv")) + list(STAGING_DIR.glob("*.xlsx"))
if not candidates:
    print("âŒ No CSV/XLSX found in _staging. Please put jp_holidays.csv or .xlsx there.")
    sys.exit(1)

RAW_PATH = candidates[0]
print(f"ğŸ“„ Using file: {RAW_PATH.name}")

# è®€æª”ï¼ˆæ”¯æ´å¤šç¨®å¸¸è¦‹æ—¥æ–‡ç·¨ç¢¼ï¼‰
def read_table(path: Path) -> pd.DataFrame:
    if path.suffix.lower() == ".xlsx":
        return pd.read_excel(path, dtype=str)
    tried = []
    for enc in ["utf-8-sig", "utf-8", "cp932", "shift_jis", "ms932", "latin1"]:
        try:
            print(f"ğŸ” Trying encoding: {enc}")
            return pd.read_csv(path, dtype=str, encoding=enc)
        except UnicodeDecodeError:
            tried.append(enc)
            continue
    print(f"âš ï¸ All encodings failed, falling back with ignore: {tried}")
    return pd.read_csv(path, dtype=str, encoding="cp932", encoding_errors="ignore")

df = read_table(RAW_PATH)

print("ğŸ§¹ Normalizing columns...")

# å»é™¤å…¨å½¢ç©ºç™½èˆ‡å‰å¾Œç©ºæ ¼
df = df.applymap(lambda x: x.strip().replace('\u3000', ' ') if isinstance(x, str) else x)

# æ¬„åæ­£è¦åŒ–ï¼ˆå»ç©ºç™½ â†’ åº•ç·š â†’ å°å¯«ï¼‰
df.columns = [re.sub(r'\s+', '_', c.strip()).lower() for c in df.columns]

# å¸¸è¦‹æ—¥æ–‡æ¬„åå°æ‡‰
rename_map = {
    "æ—¥ä»˜": "date",
    "å¹´æœˆæ—¥": "date",
    "å›½æ°‘ã®ç¥æ—¥": "holiday_name",
    "ç¥æ—¥å": "holiday_name",
    "åç§°": "holiday_name",
}
df = df.rename(columns=rename_map)

# æª¢æŸ¥æ¬„ä½
if "date" not in df.columns:
    print("âŒ 'date' column not found in source file after renaming.")
    print(f"Columns seen: {list(df.columns)}")
    sys.exit(1)

# ç¯©é¸å¿…è¦æ¬„ä½ï¼ˆè‹¥ holiday_name ä¸åœ¨å°±å…ˆå»ºç«‹ç‚ºç©ºå­—ä¸²ï¼‰
expected_cols = ["date", "holiday_name"]
for col in expected_cols:
    if col not in df.columns:
        df[col] = ""
df = df[expected_cols]

# æ—¥æœŸæ ¼å¼æ¨™æº–åŒ– â†’ YYYY-MM-DD
df["date"] = pd.to_datetime(df["date"], errors="coerce")
bad_date = df["date"].isna().sum()
if bad_date > 0:
    print(f"âš ï¸ Found {bad_date} invalid dates after coercion. They will be dropped.")
df = df.dropna(subset=["date"])
df["date"] = df["date"].dt.strftime("%Y-%m-%d")

# å»é‡ï¼ˆåŒæ—¥åŒååªç•™ä¸€åˆ—ï¼‰
df = df.drop_duplicates(subset=["date", "holiday_name"])

# æ’åºè¼¸å‡º
df = df.sort_values("date").reset_index(drop=True)

# è¼•é‡é©—è­‰
print(f"ğŸ§ª Rows: {len(df)}, unique dates: {df['date'].nunique()}")

# å¯«æª”
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
df.to_csv(OUTPUT_PATH, index=False, encoding="utf-8-sig")

print(f"âœ… Clean holidays saved to: {OUTPUT_PATH}")
